import tensorflow as tf

# import dataset
!wget --no-check-certificate \
  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip
  
# unzip dataset
import zipfile
import os
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

# creating directory
base_dir = '/tmp/rockpaperscissors/rps-cv-images/'

# data preprocessing

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    shear_range=0.2,
    fill_mode='wrap',
    validation_split=.4 #split train 0.6 val 0.4
)

test_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    shear_range=0.2,
    fill_mode='wrap',
    validation_split=.4 #split train 0.6 val 0.4
)

# preparing training data

train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(150,150), 
    batch_size=4,
    class_mode = 'sparse'
    subset = 'training' # subset training 0.6
)

validation_generator = test_datagen.flow_from_directory(
    base_dir, 
    target_size=(150,150),
    batch_size=4,
    class_mode = 'sparse' ,
    subset = 'validation' # subset val 0.4
)

# building CNN architecture

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

# Compile model dengan 'Adamax' optimizer
# dan loss function 'sparse_categorical_crossentropy'

model.compile(loss='sparse_categorical_crossentropy',
              optimizer=tf.optimizers.Adamax(),
              metrics=['accuracy'])
              
# callbacks
# minimal accuracy 98%
accuracy_threshold = 0.98

# using callbacks to stop epoch when accuracy > 98%
training_finished = False
class MyCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if (logs.get('accuracy') > accuracy_threshold):
      print("\nReached %2.2f%% accuracy, stop training." %(accuracy_threshold*100))
      self.model.stop_training = True

callbacks = MyCallback()


# training model with model.fit
history = model.fit(
    train_generator,
    steps_per_epoch=40, #batch yang akan dieksekus pada setiap epoch
    epochs=20, # tambahkan eposchs jika akurasi model belum optimal
    validation_data=validation_generator, # menampulkan akurasi pengujian data validasi
    validation_steps=5, # batch yang dieksekusi pada setiap epoch
    verbose=2,
    callbacks = [callbacks]
)

# Evaluate the model on the test data using `evaluate`
print("Evaluate on test data")
results = model.evaluate(train_generator, batch_size=128)
print("test loss, test acc:", results)

model.summary()

# class
print(train_generator.class_indices)


# looking at model result

import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
%matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():

# predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)

  print(fn)
  output_class = np.argmax(classes)
  if output_class == 0:
     print("paper")
  elif output_class == 1:
     print("rock")
  elif output_class == 2:
     print("scissors")
  else :
     print("not classified")
